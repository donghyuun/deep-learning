{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMXJ638IVQ1hFtbV8E5584",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghyuun/deep-learning/blob/main/lab_09_1_2_Neural_Net_for_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단층 뉴럴 네트워크 for Mnist"
      ],
      "metadata": {
        "id": "URg__BqNc4Q-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "webO4LdBcpj5",
        "outputId": "0a396465-b90a-47b0-beb9-c34cf6bb05c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (x_train): (60000, 28, 28)\n",
            "Training labels shape (y_train): (60000,)\n",
            "Test data shape (x_test): (10000, 28, 28)\n",
            "Test labels shape (y_test): (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5795 - loss: 1.5664\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.6901\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.5567\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.4990\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.4602\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.4393\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.4189\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.4173\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3936\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.3878\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.3762\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.3708\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.3632\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.3644\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.3587\n",
            "313/313 - 0s - 1ms/step - accuracy: 0.9082 - loss: 0.3386\n",
            "Test Loss: 0.3386\n",
            "Test Accuracy: 0.9082\n",
            "\n",
            "Layer: dense_2\n",
            "Weights (W): (784, 10)\n",
            "[[ 0.02068345  0.07653541 -0.06331408 ...  0.03348475 -0.03084585\n",
            "  -0.08280467]\n",
            " [ 0.05199686 -0.0669459  -0.0520805  ... -0.04481745  0.0710491\n",
            "   0.03081016]\n",
            " [ 0.0731402   0.00779846 -0.02643797 ... -0.04469084  0.0780058\n",
            "  -0.08481308]\n",
            " ...\n",
            " [ 0.03738805 -0.04415077  0.0232222  ...  0.07288911 -0.00119804\n",
            "   0.04949913]\n",
            " [-0.03631683 -0.04513212  0.0579396  ... -0.05792717  0.03592531\n",
            "  -0.05644386]\n",
            " [-0.06384604  0.0478703  -0.01223856 ... -0.0843695  -0.02530756\n",
            "  -0.03286747]]\n",
            "Biases (b): (10,)\n",
            "[-0.1465267   0.22860132 -0.03443635 -0.10704116  0.06812273  0.40168622\n",
            " -0.03741859  0.2193548  -0.52333903 -0.06900017]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(\"Training data shape (x_train):\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training labels shape (y_train):\", y_train.shape)  # (60000,)\n",
        "print(\"Test data shape (x_test):\", x_test.shape)  # (10000, 28, 28)\n",
        "print(\"Test labels shape (y_test):\", y_test.shape)  # (10000,)\n",
        "\n",
        "# 훈련 데이터셋에서 첫 5개의 이미지와 레이블 시각화\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(x_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 데이터 정규화: 픽셀 값을 0~1 범위로 변환\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 모델 정의\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # Dense layer with Softmax activation\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer='SGD',  # Stochastic Gradient Descent\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric to evaluate performance\n",
        ")\n",
        "\n",
        "# 모델 학습: epochs=15, batch_size=100\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=100)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 가중치와 절편 출력\n",
        "for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:  # 가중치와 절편이 있는 레이어만 처리\n",
        "        weights, biases = layer.get_weights()  # 가중치(W)와 절편(b) 가져오기\n",
        "        print(\"\\nLayer:\", layer.name)\n",
        "        print(\"Weights (W):\", weights.shape)\n",
        "        print(weights)  # 가중치 값 출력\n",
        "        print(\"Biases (b):\", biases.shape)\n",
        "        print(biases)  # 절편 값 출력\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다층 뉴럴 네트워크 for Mnist (1개 은닉층, sigmoid 사용)"
      ],
      "metadata": {
        "id": "IyT8-A3Rc7wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(\"Training data shape (x_train):\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training labels shape (y_train):\", y_train.shape)  # (60000,)\n",
        "print(\"Test data shape (x_test):\", x_test.shape)  # (10000, 28, 28)\n",
        "print(\"Test labels shape (y_test):\", y_test.shape)  # (10000,)\n",
        "\n",
        "# 훈련 데이터셋에서 첫 5개의 이미지와 레이블 시각화\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(x_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 데이터 정규화: 픽셀 값을 0~1 범위로 변환\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 모델 정의 (은닉층에 ReLU 사용 안함)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),  # 은닉층 (sigmoid 활성화)\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # 출력층 (softmax 활성화)\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer='SGD',  # Stochastic Gradient Descent\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric to evaluate performance\n",
        ")\n",
        "\n",
        "# 모델 학습: epochs=15, batch_size=100\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=100)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 가중치와 절편 출력\n",
        "for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:  # 가중치와 절편이 있는 레이어만 처리\n",
        "        weights, biases = layer.get_weights()  # 가중치(W)와 절편(b) 가져오기\n",
        "        print(\"\\nLayer:\", layer.name)\n",
        "        print(\"Weights (W):\", weights.shape)\n",
        "        print(weights)  # 가중치 값 출력\n",
        "        print(\"Biases (b):\", biases.shape)\n",
        "        print(biases)  # 절편 값 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XV-A7dxWc-rD",
        "outputId": "24cc8df0-af0f-48d0-ef3f-dc20c67cc9de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape (x_train): (60000, 28, 28)\n",
            "Training labels shape (y_train): (60000,)\n",
            "Test data shape (x_test): (10000, 28, 28)\n",
            "Test labels shape (y_test): (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4049 - loss: 2.1497\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7531 - loss: 1.4827\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 1.0719\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.8469\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8474 - loss: 0.7162\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.6306\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.5766\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.5340\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.5013\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.4749\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.4575\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.4377\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.4205\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.4132\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3982\n",
            "313/313 - 1s - 2ms/step - accuracy: 0.8992 - loss: 0.3783\n",
            "Test Loss: 0.3783\n",
            "Test Accuracy: 0.8992\n",
            "\n",
            "Layer: dense\n",
            "Weights (W): (784, 128)\n",
            "[[-0.00391954  0.05735523  0.01450442 ... -0.04412447  0.01284663\n",
            "  -0.06824662]\n",
            " [ 0.0178466  -0.00666628 -0.05441941 ... -0.08051894 -0.04210273\n",
            "  -0.08042935]\n",
            " [ 0.03427729  0.00556071 -0.04890774 ... -0.03789556  0.0392537\n",
            "   0.04930002]\n",
            " ...\n",
            " [-0.0648137  -0.03836137 -0.04726495 ... -0.01254965 -0.0799004\n",
            "  -0.04418061]\n",
            " [-0.05772398 -0.03168416 -0.04836221 ... -0.07199009 -0.01665213\n",
            "  -0.01054734]\n",
            " [-0.05146372 -0.03904352  0.06367094 ... -0.017434    0.07930904\n",
            "  -0.04658206]]\n",
            "Biases (b): (128,)\n",
            "[-0.04572804 -0.04272107 -0.02040968 -0.03051283 -0.00745765 -0.00489659\n",
            "  0.03834169  0.05613411  0.00386531 -0.03945001 -0.01485997 -0.00950318\n",
            "  0.05051487  0.02003476  0.05091687  0.00828132 -0.02615578 -0.03970776\n",
            " -0.02317053 -0.04013203  0.0441667   0.06462905 -0.00076468 -0.00952558\n",
            "  0.04320812 -0.04548478  0.04020252 -0.02909475 -0.01215702 -0.02078923\n",
            " -0.01361784  0.01654453  0.00275032  0.00719411 -0.01399178  0.02495822\n",
            "  0.03299852 -0.0402228   0.00738728 -0.03004707  0.00883393 -0.05348104\n",
            "  0.00443524  0.0224287   0.0048859   0.01353876  0.0316529  -0.01338956\n",
            "  0.05904369  0.033343   -0.05048143 -0.02838466  0.02939764  0.02520532\n",
            " -0.04682454  0.0611717  -0.01614331 -0.00627227  0.00471131  0.00703492\n",
            "  0.00074215  0.02925261 -0.02184858  0.00213928 -0.0457484  -0.01047957\n",
            " -0.03723276  0.0120231   0.03743107 -0.02096193  0.0074179  -0.00118634\n",
            "  0.04641672 -0.00884692  0.04355787  0.02938761 -0.04227411  0.0290397\n",
            " -0.0363495   0.00550574 -0.00832154  0.03243673 -0.00103714  0.01148931\n",
            " -0.01492993 -0.02797254  0.06343327  0.01853731 -0.00254966 -0.02315141\n",
            " -0.0052327  -0.022385   -0.0225504   0.02361175 -0.03492969  0.03033803\n",
            "  0.0165691   0.02240054 -0.00451221 -0.02397341  0.0366997   0.02076926\n",
            "  0.0155955  -0.01400868  0.01564852  0.02464946 -0.02076344 -0.02678751\n",
            "  0.03497484  0.00919403 -0.01593374  0.0268741  -0.00027284 -0.00686913\n",
            "  0.0432576   0.03331591 -0.00238699  0.0160505   0.04041936 -0.02769084\n",
            "  0.01518184 -0.00254007 -0.01507984  0.03374974 -0.04092393  0.00350711\n",
            "  0.05911511  0.03370874]\n",
            "\n",
            "Layer: dense_1\n",
            "Weights (W): (128, 10)\n",
            "[[ 0.255004   -0.4636953   0.37676498 ...  0.05148018  0.22245128\n",
            "   0.31877518]\n",
            " [ 0.40364048 -0.33831996  0.270422   ... -0.1783923   0.11327177\n",
            "  -0.00719635]\n",
            " [ 0.05880846 -0.07962286  0.32276577 ... -0.0060078   0.23466642\n",
            "  -0.08546539]\n",
            " ...\n",
            " [-0.17899999  0.49537277  0.39924237 ...  0.33681378 -0.02336688\n",
            "  -0.08280462]\n",
            " [-0.27471012  0.5003289   0.13386531 ... -0.02350349 -0.48881763\n",
            "   0.07848658]\n",
            " [-0.21884292  0.4733669  -0.38936532 ...  0.28878736 -0.02873677\n",
            "  -0.01172369]]\n",
            "Biases (b): (10,)\n",
            "[-0.04088091  0.03549786  0.01162109 -0.00235206 -0.02021371  0.09184326\n",
            " -0.01369913  0.02616164 -0.0541412  -0.0338365 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다층 뉴럴 네트워크 for Mnist (1개 은닉층, ReLU 사용)"
      ],
      "metadata": {
        "id": "iKlASVy8eYP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(\"Training data shape (x_train):\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training labels shape (y_train):\", y_train.shape)  # (60000,)\n",
        "print(\"Test data shape (x_test):\", x_test.shape)  # (10000, 28, 28)\n",
        "print(\"Test labels shape (y_test):\", y_test.shape)  # (10000,)\n",
        "\n",
        "# 훈련 데이터셋에서 첫 5개의 이미지와 레이블 시각화\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(x_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 데이터 정규화: 픽셀 값을 0~1 범위로 변환\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 모델 정의 (은닉층에 ReLU 사용)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # 은닉층 (ReLU 활성화)\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # 출력층 (Softmax 활성화)\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer='SGD',  # Stochastic Gradient Descent\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric to evaluate performance\n",
        ")\n",
        "\n",
        "# 모델 학습: epochs=15, batch_size=100\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=100)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 가중치와 절편 출력\n",
        "for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:  # 가중치와 절편이 있는 레이어만 처리\n",
        "        weights, biases = layer.get_weights()  # 가중치(W)와 절편(b) 가져오기\n",
        "        print(\"\\nLayer:\", layer.name)\n",
        "        print(\"Weights (W):\", weights.shape)\n",
        "        print(weights)  # 가중치 값 출력\n",
        "        print(\"Biases (b):\", biases.shape)\n",
        "        print(biases)  # 절편 값 출력\n"
      ],
      "metadata": {
        "id": "ZdD5Ru9VeWSp",
        "outputId": "738ba000-abe8-4c62-b91e-ce18ce9f5181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (x_train): (60000, 28, 28)\n",
            "Training labels shape (y_train): (60000,)\n",
            "Test data shape (x_test): (10000, 28, 28)\n",
            "Test labels shape (y_test): (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5955 - loss: 1.5099\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.5342\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.4126\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.3714\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9054 - loss: 0.3420\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.3188\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.3078\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2923\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2755\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2711\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2610\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2551\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.2459\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.2413\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2311\n",
            "313/313 - 1s - 2ms/step - accuracy: 0.9355 - loss: 0.2248\n",
            "Test Loss: 0.2248\n",
            "Test Accuracy: 0.9355\n",
            "\n",
            "Layer: dense_3\n",
            "Weights (W): (784, 128)\n",
            "[[-0.06677578 -0.03108678  0.07560157 ... -0.04690431  0.00621678\n",
            "  -0.06798603]\n",
            " [-0.02859113 -0.00616636  0.01877631 ...  0.06567996  0.00999833\n",
            "   0.07804065]\n",
            " [ 0.05310672  0.02191557  0.07758897 ... -0.00329442  0.02806041\n",
            "   0.05885064]\n",
            " ...\n",
            " [ 0.01695304 -0.05277902  0.07370528 ... -0.0600852   0.05240565\n",
            "   0.06433348]\n",
            " [ 0.0168108   0.0789158  -0.03312519 ...  0.0201507   0.06603777\n",
            "   0.01867741]\n",
            " [ 0.00715896  0.05680323  0.01784919 ...  0.04098194 -0.06599052\n",
            "  -0.01287747]]\n",
            "Biases (b): (128,)\n",
            "[-0.06787722  0.04221809  0.04813252 -0.0178173  -0.04328695  0.07933088\n",
            "  0.03066239  0.05344735 -0.02659077  0.03453668  0.04355417 -0.11370096\n",
            " -0.07161573  0.05899347 -0.10807122  0.00918599 -0.05746268 -0.01549367\n",
            "  0.03647253 -0.02410258  0.02433771  0.01116239  0.01331533 -0.04396667\n",
            "  0.02255577  0.02402009  0.08186445  0.07628627  0.06276077  0.09902576\n",
            " -0.03132097 -0.01995645 -0.01722994 -0.00077158  0.0379127   0.03925852\n",
            " -0.01229753  0.05056118  0.01771966 -0.04231859  0.07775953  0.04303079\n",
            "  0.04327096  0.01929569  0.04373919 -0.00533452  0.00639705  0.00744314\n",
            "  0.01848183  0.0004268   0.02674055  0.00544553  0.02177564 -0.01203707\n",
            "  0.10879327  0.03111822  0.04433453  0.00802924  0.05573599  0.11163925\n",
            " -0.01441069  0.03215256 -0.04044202  0.03156115  0.04020369  0.09721021\n",
            "  0.0361812   0.00594022 -0.04249123  0.05597569 -0.03410706  0.00255524\n",
            "  0.02656888 -0.00224905 -0.00360142  0.09995762  0.00496017  0.01632673\n",
            " -0.0051625  -0.06968594 -0.00136175  0.00588606  0.01790475  0.00272108\n",
            "  0.00606555  0.02930105  0.07582203  0.07027657  0.01864449  0.11867107\n",
            "  0.03459949 -0.05653196 -0.00668989  0.04779203  0.01386241  0.02112711\n",
            "  0.08393461  0.02302657  0.0322159   0.01896384  0.0685323  -0.02113122\n",
            "  0.0197529   0.07484067  0.0507199   0.02238263  0.13911638  0.0250469\n",
            " -0.01210766  0.0046468   0.05132496 -0.0036592   0.0284891   0.08920774\n",
            "  0.0540363   0.00765573  0.05090692 -0.00797563 -0.01857356  0.0267579\n",
            "  0.06893273  0.00618123  0.00962477  0.05103999 -0.01233114  0.04889233\n",
            "  0.03828538  0.0284006 ]\n",
            "\n",
            "Layer: dense_4\n",
            "Weights (W): (128, 10)\n",
            "[[-0.2245353  -0.13697755  0.04415151 ... -0.28846034  0.3006993\n",
            "   0.24925646]\n",
            " [-0.27657196 -0.00993889  0.15661357 ...  0.24333395 -0.12948237\n",
            "   0.18193375]\n",
            " [-0.20625573 -0.27282852  0.19410147 ... -0.13667832 -0.16059642\n",
            "  -0.20819446]\n",
            " ...\n",
            " [ 0.0746944  -0.15129694  0.1201999  ...  0.0149273  -0.15744835\n",
            "   0.09095179]\n",
            " [-0.15245801  0.22678988 -0.13824993 ...  0.10968451 -0.16895597\n",
            "  -0.16346118]\n",
            " [ 0.35804826 -0.32455495 -0.10778234 ...  0.12029066  0.03450536\n",
            "  -0.12882525]]\n",
            "Biases (b): (10,)\n",
            "[-0.10976535  0.08134343 -0.00051525 -0.0264625   0.02799824  0.19085628\n",
            "  0.01205184  0.10038698 -0.19352868 -0.08236542]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다층 뉴럴 네트워크 for Mnist (3개 은닉층, ReLU 사용)"
      ],
      "metadata": {
        "id": "yfUTWMWzfHbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(\"Training data shape (x_train):\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training labels shape (y_train):\", y_train.shape)  # (60000,)\n",
        "print(\"Test data shape (x_test):\", x_test.shape)  # (10000, 28, 28)\n",
        "print(\"Test labels shape (y_test):\", y_test.shape)  # (10000,)\n",
        "\n",
        "# 훈련 데이터셋에서 첫 5개의 이미지와 레이블 시각화\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(x_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 데이터 정규화: 픽셀 값을 0~1 범위로 변환\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 모델 정의 (은닉층 2개 추가)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # 첫 번째 은닉층\n",
        "    tf.keras.layers.Dense(64, activation='relu'),   # 두 번째 은닉층 (추가된 레이어)\n",
        "    tf.keras.layers.Dense(32, activation='relu'),   # 세 번째 은닉층 (추가된 레이어)\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # 출력층 (Softmax 활성화)\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer='SGD',  # Stochastic Gradient Descent\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric to evaluate performance\n",
        ")\n",
        "\n",
        "# 모델 학습: epochs=15, batch_size=100\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=100)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 가중치와 절편 출력\n",
        "for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:  # 가중치와 절편이 있는 레이어만 처리\n",
        "        weights, biases = layer.get_weights()  # 가중치(W)와 절편(b) 가져오기\n",
        "        print(\"\\nLayer:\", layer.name)\n",
        "        print(\"Weights (W):\", weights.shape)\n",
        "        print(weights)  # 가중치 값 출력\n",
        "        print(\"Biases (b):\", biases.shape)\n",
        "        print(biases)  # 절편 값 출력\n"
      ],
      "metadata": {
        "id": "1bdZQrmHfEO9",
        "outputId": "01071366-c2bd-4696-f456-f91c9c8982b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (x_train): (60000, 28, 28)\n",
            "Training labels shape (y_train): (60000,)\n",
            "Test data shape (x_test): (10000, 28, 28)\n",
            "Test labels shape (y_test): (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4522 - loss: 1.8230\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.5033\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.3700\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.3185\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2877\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2643\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.2387\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.2175\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1996\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1875\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1768\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1700\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1599\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9565 - loss: 0.1530\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.1431\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9578 - loss: 0.1431\n",
            "Test Loss: 0.1431\n",
            "Test Accuracy: 0.9578\n",
            "\n",
            "Layer: dense_5\n",
            "Weights (W): (784, 128)\n",
            "[[-0.06210847 -0.07026637 -0.02090495 ... -0.01727565 -0.03843742\n",
            "  -0.00507157]\n",
            " [ 0.00999928 -0.01197194 -0.06898886 ... -0.07523765  0.02263644\n",
            "  -0.02616952]\n",
            " [ 0.01013739 -0.02220519  0.05832424 ... -0.04400163  0.00906009\n",
            "   0.06373098]\n",
            " ...\n",
            " [ 0.05611912  0.02507982  0.00115266 ... -0.04815904 -0.07114309\n",
            "   0.03565845]\n",
            " [ 0.01630557  0.08014781 -0.00232255 ... -0.00936726 -0.01849689\n",
            "  -0.02448888]\n",
            " [ 0.02442381 -0.05725808  0.07512673 ... -0.0438366   0.0476621\n",
            "  -0.05991396]]\n",
            "Biases (b): (128,)\n",
            "[ 0.01519456  0.06469395 -0.05839423  0.04233637  0.04753641 -0.00703631\n",
            " -0.00359343  0.03400997  0.00202674 -0.00446272 -0.00560604  0.00967296\n",
            " -0.01942356 -0.0231381   0.00680201  0.04121402 -0.00263017 -0.00463618\n",
            " -0.01663581  0.02259285  0.00927822 -0.00681358  0.06430918  0.09522651\n",
            "  0.0014367   0.01975359 -0.01234323  0.00088512 -0.00084244  0.00732898\n",
            "  0.02646693 -0.00759955  0.027313    0.05011133 -0.00838022  0.00361617\n",
            "  0.00633213  0.00844327  0.00929888 -0.00203181 -0.02237623 -0.00104849\n",
            " -0.04393965  0.00246942  0.05032482  0.02133916  0.03714124  0.0381536\n",
            "  0.00829274  0.04213151  0.01710517  0.01190505 -0.00514145  0.03353451\n",
            " -0.01344055  0.0028984   0.02806044  0.02494866  0.04423941 -0.00026352\n",
            "  0.04187433 -0.00988195  0.04171421  0.01515117  0.05612631  0.01191399\n",
            "  0.01738347  0.03343626  0.01771792 -0.00384168  0.01331632  0.00662071\n",
            "  0.07996786  0.06922077  0.01256547  0.00399028 -0.0051538   0.0201438\n",
            " -0.00946901  0.04504728 -0.00946359  0.00928767  0.04082461  0.02706032\n",
            " -0.0035751   0.00843879  0.00688978 -0.00869749  0.01986201 -0.00652334\n",
            "  0.00065472 -0.0201323   0.0271527   0.0026566   0.00329375 -0.00494034\n",
            "  0.01029236  0.0183184   0.00222808  0.04925091  0.00879278  0.0633741\n",
            "  0.04497219 -0.00877049 -0.00196782  0.00685686  0.00791543  0.05037868\n",
            "  0.00952815 -0.0022825   0.0009866   0.00572183 -0.02129077  0.06465168\n",
            "  0.01055237  0.09612445  0.01038666 -0.00189961  0.02570685 -0.01996489\n",
            "  0.0204464   0.00973246  0.02645311  0.04308    -0.01296419  0.00807217\n",
            "  0.01448238  0.01141571]\n",
            "\n",
            "Layer: dense_6\n",
            "Weights (W): (128, 64)\n",
            "[[-1.16240419e-01 -1.71300210e-02  1.33023649e-01 ... -5.89404926e-02\n",
            "  -1.57401666e-01 -4.78761755e-02]\n",
            " [ 1.27001122e-01  1.52154773e-01  3.98792885e-03 ...  1.09554708e-01\n",
            "   1.53078604e-02 -1.42851636e-01]\n",
            " [ 1.38349235e-01 -9.88184111e-05 -1.71234265e-01 ...  3.95505875e-02\n",
            "  -2.49637574e-01 -8.86551570e-03]\n",
            " ...\n",
            " [-8.70581269e-02 -1.66101396e-01  9.13899243e-02 ...  1.02206595e-01\n",
            "   1.82193145e-01 -1.03366174e-01]\n",
            " [-7.84769327e-07  1.84603781e-02 -6.95286393e-02 ...  9.83388796e-02\n",
            "  -5.32307588e-02 -4.89028729e-02]\n",
            " [ 1.59407750e-01 -5.13620786e-02  7.15323612e-02 ...  3.22781801e-02\n",
            "   1.40059739e-01  8.85992795e-02]]\n",
            "Biases (b): (64,)\n",
            "[ 0.02852758  0.04073925 -0.0056956  -0.02480656  0.05370997  0.00975844\n",
            "  0.00382356  0.09279103  0.01611569  0.03736228  0.00197866  0.02928518\n",
            "  0.08300111  0.03770658 -0.00531306  0.02619366  0.0382577   0.05119944\n",
            " -0.02460391  0.04532683  0.00576054  0.0115829   0.0377181   0.00414006\n",
            "  0.03666094  0.04063589  0.06762    -0.00668851  0.1054782  -0.00486794\n",
            "  0.07318391  0.01612195 -0.00926932  0.01072317 -0.00290383  0.01044653\n",
            "  0.01333765  0.00627436  0.01437635  0.05301775  0.01153955  0.01584825\n",
            "  0.00045333  0.0434268   0.01945404  0.04414461  0.02681958  0.01103551\n",
            "  0.07459322  0.01799728  0.08017179 -0.03448645  0.00609812  0.04418336\n",
            "  0.06273589 -0.02479956 -0.00596673  0.04893516  0.07059301  0.00210883\n",
            "  0.00980116  0.03543362  0.0964662  -0.00715492]\n",
            "\n",
            "Layer: dense_7\n",
            "Weights (W): (64, 32)\n",
            "[[ 0.02239414  0.01279066 -0.18117027 ... -0.26153198 -0.25150087\n",
            "  -0.15370479]\n",
            " [-0.36015603  0.18896157  0.11304326 ... -0.0974456   0.15456298\n",
            "  -0.09033999]\n",
            " [-0.09874403  0.06660458  0.05631975 ... -0.04440829  0.1260396\n",
            "   0.20848623]\n",
            " ...\n",
            " [-0.20846412  0.13780884 -0.02194156 ... -0.18319277  0.32110706\n",
            "  -0.09866956]\n",
            " [-0.11948144 -0.03399559  0.09548193 ...  0.0285781   0.35433245\n",
            "  -0.23123041]\n",
            " [-0.02233567  0.01091721 -0.03955232 ...  0.10607053  0.18816473\n",
            "   0.13339293]]\n",
            "Biases (b): (32,)\n",
            "[-0.04042524 -0.03592958 -0.00281672 -0.00162672  0.08661503  0.01483375\n",
            "  0.03179788 -0.01287886  0.01653899  0.00667708  0.00639247  0.05250409\n",
            " -0.00854753  0.06065324  0.02313802  0.04465756  0.05752542 -0.01513888\n",
            "  0.00692137  0.01692103 -0.04900717  0.04489873  0.00656351 -0.05013201\n",
            " -0.06684317  0.08902672 -0.00798974  0.08098984  0.03346457  0.0343279\n",
            "  0.08697779 -0.00364236]\n",
            "\n",
            "Layer: dense_8\n",
            "Weights (W): (32, 10)\n",
            "[[-0.13905396 -0.50052965  0.19810985  0.05146569 -0.15250263 -0.29631594\n",
            "   0.44155708 -0.59824216  0.2084529   0.1050714 ]\n",
            " [ 0.02098334 -0.24965553 -0.25434592  0.34799135  0.30437723  0.27662554\n",
            "  -0.2354434   0.04258945  0.29915294  0.202237  ]\n",
            " [ 0.1349036  -0.25880805 -0.00862885  0.20007774 -0.03310647  0.15316911\n",
            "   0.01954338  0.19002776  0.29499933  0.19834161]\n",
            " [-0.09213222 -0.33240038 -0.20724507 -0.0570908   0.2710306   0.26121756\n",
            "   0.26932085 -0.14867127 -0.24186483  0.35500666]\n",
            " [-0.1259197  -0.19411206 -0.33078992 -0.19854394  0.697966    0.1570293\n",
            "  -0.48657265  0.11490058 -0.43103302  0.40438113]\n",
            " [ 0.30931488 -0.410747    0.280153   -0.560365   -0.45766065  0.48299927\n",
            "   0.30640066  0.20212163  0.48168156  0.1770037 ]\n",
            " [-0.2105874   0.09506842 -0.44079277  0.08672834 -0.01711274  0.2653167\n",
            "  -0.51576585  0.13184384  0.2864739   0.05153037]\n",
            " [ 0.04926005 -0.32117352  0.37226063 -0.46389225 -0.08601476 -0.47493982\n",
            "  -0.06093071 -0.05021486 -0.250957    0.4471404 ]\n",
            " [-0.26903096 -0.13255943 -0.47355503  0.22466731 -0.39441258  0.19387653\n",
            "   0.38263166 -0.11857076 -0.37616348  0.2696466 ]\n",
            " [-0.40047905 -0.24198027  0.21644963  0.347171   -0.25396568  0.20245504\n",
            "  -0.07974967  0.01696746 -0.07269458  0.02118633]\n",
            " [ 0.29259306 -0.16624127 -0.21502632 -0.39092088 -0.13144039 -0.00664324\n",
            "  -0.01441566  0.29078597 -0.35113165 -0.37952003]\n",
            " [ 0.6148513  -0.2131912   0.44536114  0.2872627  -0.26208934  0.04478691\n",
            "  -0.56486094  0.2822657  -0.51928043 -0.3108533 ]\n",
            " [-0.2870185   0.09183133  0.33990985 -0.22204274  0.2946274  -0.32894257\n",
            "   0.25079525 -0.24587055 -0.1409622   0.16377732]\n",
            " [-0.0771336   0.16018482  0.1431029  -0.14445446  0.30742466  0.41716614\n",
            "   0.3714993  -0.33278307 -0.14554688 -0.34210572]\n",
            " [ 0.28901538  0.14252459  0.34887254  0.4275721   0.29368672 -0.08421107\n",
            "  -0.1097091   0.3553301   0.01979564  0.04705851]\n",
            " [-0.353313   -0.47095525 -0.3265253   0.19436102 -0.38229865 -0.15574822\n",
            "  -0.39599642  0.5924573  -0.53209966  0.5436905 ]\n",
            " [-0.48108485 -0.06564723 -0.2724348   0.08681416  0.50672156  0.43251884\n",
            "  -0.35671324 -0.04140813  0.13386177  0.25656357]\n",
            " [-0.26280466  0.07927554 -0.03218313  0.19120042 -0.3105244   0.31452453\n",
            "  -0.1786593  -0.2922487   0.13235867 -0.33513623]\n",
            " [-0.07550441 -0.2611699  -0.01694301 -0.14951782  0.53706604 -0.18957399\n",
            "   0.27992535  0.37481958  0.0839479  -0.5569747 ]\n",
            " [-0.02730657  0.62271374  0.49868706  0.5676559  -0.02334915 -0.16820827\n",
            "  -0.38786566 -0.04784007  0.24651812 -0.41745567]\n",
            " [-0.36948487  0.44041458 -0.3735332  -0.0555718  -0.46082357 -0.7360324\n",
            "  -0.10650727  0.27251458  0.4523007   0.25694552]\n",
            " [-0.45829952 -0.33715078  0.14941895  0.6340687   0.3262134   0.2159083\n",
            "  -0.4466023  -0.18146347  0.30708995  0.11587842]\n",
            " [-0.4654073   0.19790363 -0.10801785 -0.01769674  0.4550792   0.02832728\n",
            "   0.35885295 -0.6145801   0.35769692 -0.09125461]\n",
            " [ 0.21278551 -0.5158029   0.3269658   0.27660802  0.35748395 -0.01797685\n",
            "  -0.07842396 -0.26720196  0.3273287   0.02080569]\n",
            " [ 0.5053207   0.11099136  0.22514324  0.02870274  0.3310629  -0.5158855\n",
            "   0.34334686  0.20458816  0.41781372 -0.09717907]\n",
            " [-0.6027374   0.2247737   0.15624142  0.08720252 -0.35455027 -0.14478926\n",
            "  -0.15639657 -0.22154805 -0.36849916 -0.6690092 ]\n",
            " [-0.05307701  0.31733117  0.26806727  0.21656145  0.11220016  0.26784116\n",
            "   0.02112165 -0.35424688 -0.2891858  -0.10493013]\n",
            " [-0.38656664  0.57057863  0.39351532 -0.57291543 -0.29089656 -0.42249978\n",
            "   0.43721706  0.2768645  -0.67767406  0.28022736]\n",
            " [-0.14934595  0.11613431 -0.61672246 -0.18840809  0.29075035  0.2259235\n",
            "   0.31791058  0.3207848   0.10075972  0.44950566]\n",
            " [ 0.03762991  0.02708209  0.06515203 -0.32724863 -0.19889943  0.07331271\n",
            "  -0.3457937   0.4211649   0.52823687 -0.47665164]\n",
            " [ 0.53969     0.38207802 -0.45283455 -0.2822219  -0.45361575  0.6917468\n",
            "   0.35636994 -0.34038514 -0.15990889 -0.08003303]\n",
            " [ 0.10418032  0.02012235 -0.01572437 -0.24484184  0.36326337  0.28281432\n",
            "   0.17735986 -0.28930187  0.3078439   0.20728803]]\n",
            "Biases (b): (10,)\n",
            "[-0.01974967  0.0542161   0.02310335  0.02386887  0.01344711  0.22484554\n",
            " -0.00616981 -0.00681622 -0.17052737 -0.13621809]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다층 뉴럴 네트워크 for Mnist (3개 은닉층, ReLU 사용, 뉴런 수 추가)"
      ],
      "metadata": {
        "id": "RMfwV3nygCN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(\"Training data shape (x_train):\", x_train.shape)  # (60000, 28, 28)\n",
        "print(\"Training labels shape (y_train):\", y_train.shape)  # (60000,)\n",
        "print(\"Test data shape (x_test):\", x_test.shape)  # (10000, 28, 28)\n",
        "print(\"Test labels shape (y_test):\", y_test.shape)  # (10000,)\n",
        "\n",
        "# 훈련 데이터셋에서 첫 5개의 이미지와 레이블 시각화\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(x_train[i], cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 데이터 정규화: 픽셀 값을 0~1 범위로 변환\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 모델 정의 (은닉층 3개)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),  # 첫 번째 은닉층 (512개의 뉴런)\n",
        "    tf.keras.layers.Dense(256, activation='relu'),  # 두 번째 은닉층 (256개의 뉴런)\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # 세 번째 은닉층 (128개의 뉴런)\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # 출력층 (10개의 클래스)\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer='SGD',  # Stochastic Gradient Descent\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "    metrics=['accuracy']  # Metric to evaluate performance\n",
        ")\n",
        "\n",
        "# 모델 학습: epochs=15, batch_size=100\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=100)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 가중치와 절편 출력\n",
        "for layer in model.layers:\n",
        "    if len(layer.get_weights()) > 0:  # 가중치와 절편이 있는 레이어만 처리\n",
        "        weights, biases = layer.get_weights()  # 가중치(W)와 절편(b) 가져오기\n",
        "        print(\"\\nLayer:\", layer.name)\n",
        "        print(\"Weights (W):\", weights.shape)\n",
        "        print(weights)  # 가중치 값 출력\n",
        "        print(\"Biases (b):\", biases.shape)\n",
        "        print(biases)  # 절편 값 출력\n"
      ],
      "metadata": {
        "id": "c9vdlbUEf-iZ",
        "outputId": "bbc676e4-bbb5-46a8-85dc-36f1a4be41c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape (x_train): (60000, 28, 28)\n",
            "Training labels shape (y_train): (60000,)\n",
            "Test data shape (x_test): (10000, 28, 28)\n",
            "Test labels shape (y_test): (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5417 - loss: 1.6859\n",
            "Epoch 2/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8897 - loss: 0.4162\n",
            "Epoch 3/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9126 - loss: 0.3113\n",
            "Epoch 4/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.2690\n",
            "Epoch 5/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9301 - loss: 0.2444\n",
            "Epoch 6/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9408 - loss: 0.2125\n",
            "Epoch 7/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9445 - loss: 0.1957\n",
            "Epoch 8/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9484 - loss: 0.1825\n",
            "Epoch 9/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9523 - loss: 0.1649\n",
            "Epoch 10/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9561 - loss: 0.1574\n",
            "Epoch 11/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.1481\n",
            "Epoch 12/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1326\n",
            "Epoch 13/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.1276\n",
            "Epoch 14/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.1211\n",
            "Epoch 15/15\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9679 - loss: 0.1134\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9626 - loss: 0.1223\n",
            "Test Loss: 0.1223\n",
            "Test Accuracy: 0.9626\n",
            "\n",
            "Layer: dense_9\n",
            "Weights (W): (784, 512)\n",
            "[[ 0.06148633 -0.02964344  0.04671001 ...  0.04672854  0.06124535\n",
            "  -0.01875603]\n",
            " [-0.0556461  -0.05876117 -0.05112292 ... -0.00620193 -0.04606172\n",
            "  -0.05447073]\n",
            " [ 0.00744697  0.06269075 -0.02068269 ... -0.04378605 -0.02020558\n",
            "  -0.03056506]\n",
            " ...\n",
            " [-0.03228207 -0.00110912  0.02194726 ...  0.01045462 -0.06722993\n",
            "   0.03491878]\n",
            " [ 0.06070334 -0.02431852 -0.06485282 ... -0.00151708  0.02734626\n",
            "  -0.04200751]\n",
            " [ 0.06040651  0.04530522 -0.05469239 ...  0.04908069 -0.05362152\n",
            "  -0.01143906]]\n",
            "Biases (b): (512,)\n",
            "[ 4.24709916e-03  8.39263201e-03  5.43903885e-03 -4.04759310e-03\n",
            "  2.76511884e-04 -6.45408547e-03  1.18979784e-02  1.46605717e-02\n",
            "  3.49004427e-03  1.72910579e-02 -1.71601295e-03  1.35736456e-02\n",
            "  6.28429232e-03  8.92136339e-03  4.62551310e-04  9.02985223e-03\n",
            "  1.86315668e-03 -7.15990784e-03  2.48624459e-02 -4.55911178e-03\n",
            " -2.81289592e-03 -3.02618486e-03  6.88637327e-03  8.81131552e-03\n",
            "  1.85635071e-02  6.04181690e-03  1.55814756e-02  2.36438550e-02\n",
            "  6.11679908e-03 -2.49189418e-03  1.37603329e-02  1.79946870e-02\n",
            "  2.84159859e-03  2.20796122e-04 -5.34121040e-03 -1.99018791e-03\n",
            "  6.38212962e-03  1.19605130e-02  2.53163045e-03  9.53555852e-03\n",
            " -1.69129297e-02  2.45831739e-02 -2.59475992e-03 -4.11808863e-03\n",
            "  7.50071602e-04  3.08749750e-02  9.24436375e-03  2.29238775e-02\n",
            "  3.57971038e-03  8.29383172e-03 -3.84177174e-03 -8.61462113e-03\n",
            " -2.40282109e-03  8.30370933e-03  9.97770298e-03 -6.83551421e-03\n",
            " -4.00977442e-03  4.19558352e-03  4.82069096e-03  4.06320702e-04\n",
            "  2.96034315e-03  2.08087601e-02 -1.10910442e-02  1.54493172e-02\n",
            "  3.83422058e-03  1.07044056e-02  1.25218360e-02  7.00231828e-03\n",
            "  9.35215270e-04  6.31150603e-03 -5.30254235e-03 -3.41239059e-03\n",
            "  1.47625934e-02 -1.98282558e-03  1.19639263e-02 -2.32661068e-02\n",
            "  2.21548546e-02  1.32770995e-02 -6.21317513e-03  2.32996121e-02\n",
            " -1.23809204e-02  3.46325710e-02  9.41838138e-03  7.93555938e-03\n",
            "  3.60661978e-03  2.00734697e-02  7.38925161e-03  1.57570168e-02\n",
            "  4.54840576e-03 -3.76411976e-04 -2.80381599e-03  1.69938169e-02\n",
            "  2.46348581e-03  2.79201325e-02 -7.09810047e-05  2.02837307e-02\n",
            " -2.38494063e-03 -2.32124934e-03  1.08198049e-02  1.92044750e-02\n",
            " -5.41698374e-03  6.85353205e-03  9.53615457e-03  1.03615858e-02\n",
            "  2.10079644e-02 -4.94057429e-04  1.92765910e-02  4.14331583e-03\n",
            " -1.64829788e-03  1.91541407e-02  3.48108099e-03  2.97283102e-03\n",
            "  1.40002212e-02  6.82566036e-03  9.37884953e-03  1.14469174e-02\n",
            "  9.65337735e-03  2.38984544e-02  8.21748376e-03 -1.24486256e-02\n",
            "  1.06002688e-02  8.05616938e-03  1.28832867e-03 -3.51303344e-04\n",
            "  1.45517604e-03  1.28246360e-02  7.85080902e-03  4.42729145e-03\n",
            " -2.13111062e-02  2.64775241e-03  1.09126223e-02 -5.68026863e-03\n",
            "  2.61252970e-02  8.11550487e-03  1.05481027e-02 -6.59106809e-05\n",
            "  1.15912184e-02  1.33496029e-02  4.83590271e-03  1.31578445e-02\n",
            "  1.72845032e-02  9.59268957e-03 -7.74963619e-03 -7.03410478e-05\n",
            "  4.02105972e-03  1.81883033e-02  1.20469239e-02  1.67037491e-02\n",
            "  6.72758091e-03  2.03280449e-02 -1.19577115e-03 -4.10078466e-03\n",
            "  1.08244997e-02  2.96253972e-02  7.37321982e-03  1.78949386e-02\n",
            "  5.19191939e-03  1.45113217e-02  3.13524064e-03  5.31722698e-03\n",
            "  3.14429738e-02  4.24537016e-03 -7.24250404e-03  1.26062902e-02\n",
            " -4.44813399e-03  3.87317059e-03  1.55275529e-02  3.20460601e-03\n",
            " -4.74444067e-04  1.90378152e-04  7.27474364e-03  1.79598872e-02\n",
            "  1.92373507e-02  8.14557483e-04  1.71820559e-02  2.18713041e-02\n",
            "  1.34416623e-02 -3.72626306e-03  7.70360837e-03  9.99039912e-05\n",
            "  3.27545498e-03  1.29742753e-02  1.40368333e-02  2.14707982e-02\n",
            "  8.05313047e-03  3.45874429e-02 -2.89939786e-03  6.38667541e-03\n",
            " -6.47369493e-03 -1.05275465e-02  2.80849971e-02 -5.56282140e-03\n",
            " -1.40634440e-02  2.14970158e-03  1.00360392e-02  1.85174178e-02\n",
            "  1.26081193e-02  4.39461926e-03 -4.28487873e-03 -9.93380789e-03\n",
            " -1.62195805e-02  3.04311905e-02  2.16363985e-02  5.39685367e-03\n",
            " -6.71787793e-03  9.44496598e-03  1.03034219e-02 -9.82622430e-03\n",
            "  1.73146147e-02  7.33821653e-03  3.32491030e-03  1.52405510e-02\n",
            "  4.66311770e-03  3.70041542e-02  6.67429063e-03  7.74609577e-03\n",
            "  2.09304485e-02  1.84300952e-02  1.39349652e-02  2.89355242e-03\n",
            "  1.15963677e-02 -8.80417973e-03  1.93297062e-02  1.31202897e-03\n",
            "  1.40600912e-02 -6.06780872e-03  1.73444133e-02  5.82544133e-03\n",
            " -1.89576705e-03 -3.29052913e-04 -1.36113772e-03  6.60204038e-04\n",
            " -2.30842573e-03 -2.61518336e-03  2.21512076e-02  3.38162319e-03\n",
            "  1.98723096e-02  1.39623117e-02  3.13095306e-03 -1.97090525e-02\n",
            "  1.09032057e-02  1.55607623e-03 -3.89899546e-03  1.53991729e-02\n",
            " -3.01639154e-03  1.96687672e-02  2.13884115e-02  7.92941917e-03\n",
            "  2.07883660e-02  9.97916516e-03  9.94304544e-04  4.37028753e-03\n",
            "  1.53984828e-03  7.73987221e-03 -3.61820008e-03 -2.75325915e-03\n",
            "  4.02851356e-03  5.35385218e-03  5.50621480e-04  3.38604786e-02\n",
            " -3.10731423e-03  8.13366659e-03  4.34832554e-03  7.71691278e-03\n",
            "  7.11530354e-03  1.33034112e-02  1.61226206e-02 -2.95570726e-03\n",
            " -2.75072642e-03  4.10547061e-03  1.16810212e-02  1.38095310e-02\n",
            "  1.27793360e-03  6.32435689e-03  1.16128745e-02  1.41721023e-02\n",
            "  1.86312300e-05  2.45159934e-03  3.20153590e-03 -3.50315822e-04\n",
            "  2.38272105e-03  2.71024462e-02  8.21642578e-03  1.19058136e-03\n",
            "  7.53479125e-03  9.48512740e-03  4.91479412e-03  2.08405070e-02\n",
            "  8.99234042e-03  6.84933458e-03 -1.82466931e-03  1.19587360e-02\n",
            "  1.14960158e-02  3.63455643e-03  7.05914479e-03 -1.99753698e-03\n",
            "  1.94195714e-02  1.65190846e-02 -5.60233882e-03 -1.36821310e-03\n",
            "  1.31059485e-02 -5.40728634e-03 -1.36375159e-03  1.54994568e-02\n",
            " -1.94617733e-03 -1.38634341e-02 -6.38050539e-03  2.97538191e-02\n",
            "  1.59404352e-02  7.35684007e-05  1.46871218e-02 -9.74523183e-03\n",
            "  8.88055936e-03  6.48815557e-03 -1.81737752e-03  7.06301583e-03\n",
            "  1.90538529e-04  1.57200862e-02  1.42342625e-02  9.14107310e-04\n",
            "  3.13258320e-02  1.06232101e-02 -3.37605411e-03  1.51933786e-02\n",
            "  1.20049830e-04  1.33664999e-02  2.50750058e-03 -2.16529495e-03\n",
            " -1.96900172e-03  1.83097292e-02  1.06752235e-02  1.20914057e-02\n",
            "  1.24360919e-02  1.48302410e-02  1.48630431e-02 -1.66600738e-02\n",
            "  1.97731070e-02  9.71713662e-03 -4.99928696e-03  2.86026113e-02\n",
            "  1.43420426e-02  2.25221645e-02  3.50427901e-04 -6.23300578e-03\n",
            " -1.44045590e-03  5.37128141e-03  3.73563431e-02 -3.24937934e-03\n",
            "  8.01913626e-03 -7.89692684e-04  1.43429022e-02  9.34829004e-05\n",
            " -5.52325835e-03 -6.51462656e-03 -9.56139341e-03  4.35702549e-03\n",
            "  1.21032195e-02 -4.23275679e-03 -3.17532406e-03  5.16949873e-03\n",
            " -1.06796157e-02  1.97890941e-02 -4.90056537e-03  2.94043520e-03\n",
            "  1.20116202e-02  1.90095194e-02  1.09339943e-02  5.38012804e-03\n",
            "  1.69344265e-02  1.21314115e-04  1.93180162e-02 -6.02784567e-03\n",
            "  1.68021140e-03  2.05463246e-02  2.59661395e-03 -4.32857359e-03\n",
            "  2.00936105e-02  4.70137224e-04  2.77468208e-02  3.47561715e-03\n",
            "  3.22333211e-03 -1.11038575e-03 -3.81506979e-03 -4.19465173e-03\n",
            "  3.09869274e-03  1.53379105e-02  6.81584189e-03 -7.41827395e-03\n",
            "  1.37151722e-02  2.68006418e-03  1.14504911e-03  1.41717494e-02\n",
            "  3.22472351e-03  1.01843318e-02  4.58293967e-03  4.22861287e-03\n",
            " -6.95415726e-03  1.40104741e-02  1.51288649e-02  8.71593785e-03\n",
            "  7.51054939e-03  1.02914125e-02  1.60715822e-02  1.69306831e-03\n",
            "  1.43733574e-02  1.87353622e-02  9.31574963e-03 -1.59630943e-02\n",
            "  8.67515616e-03 -6.02272514e-04  1.66416876e-02  1.84872765e-02\n",
            "  9.62642953e-04  2.83895470e-02  1.38289090e-02  9.71742813e-03\n",
            "  3.49278981e-03 -4.74394439e-03 -1.51087297e-03  5.06563717e-03\n",
            "  3.41982432e-02  1.68693867e-02  1.94147676e-02  1.48965716e-02\n",
            "  1.57963466e-02  2.02087332e-02  1.39290292e-03  1.10137751e-02\n",
            " -5.22727193e-03  2.34369002e-02 -5.21759968e-04  2.37638084e-03\n",
            "  4.43381863e-03  1.73449628e-02  1.43555328e-02  2.63684173e-03\n",
            "  2.49643251e-03  2.36850884e-03  1.38423881e-02 -4.08523204e-03\n",
            "  8.96005146e-03  1.73241161e-02  1.40873322e-04  2.09425725e-02\n",
            "  5.56951296e-03  1.68047044e-02  3.46272881e-03  3.94622516e-03\n",
            "  2.46290118e-02  8.11689254e-03  3.92231625e-03 -1.36136761e-04\n",
            "  1.79676898e-02  2.02524662e-02  1.26884319e-02 -4.66784695e-03\n",
            " -4.85550176e-04  9.73667391e-03 -5.74246328e-03  2.06023864e-02\n",
            " -2.74066464e-03  7.62218051e-03  8.78829882e-03  5.53781865e-03\n",
            "  1.11771692e-02  1.69121139e-02  1.32396556e-02  3.10591962e-02\n",
            "  2.74318480e-03  1.13486713e-02 -2.02009291e-03  1.36168664e-02\n",
            "  2.06957292e-02  1.89540908e-02  1.48539739e-02  7.78857712e-03\n",
            "  1.06686521e-02 -3.30012664e-03 -2.40990776e-05  1.17604272e-03\n",
            "  1.57559477e-02  2.26018876e-02  8.95433873e-03  1.19541958e-02\n",
            "  8.60974845e-03 -1.50253042e-03  2.18610801e-02  7.36488216e-03\n",
            "  1.97185725e-02  2.64941864e-02  2.19699740e-02  3.28740925e-02\n",
            "  3.05968001e-02 -8.25288706e-03  9.03730746e-03  1.23348823e-02\n",
            "  5.97688020e-04 -1.38132973e-03  5.49936248e-03  2.21882015e-02\n",
            " -4.35604993e-03  1.61492229e-02 -8.72376841e-03  3.08468868e-03\n",
            " -1.12116486e-02  8.80727451e-03 -1.78683025e-04  8.95558298e-03\n",
            " -4.39263042e-03  6.09959662e-03  6.48741797e-03  1.15568228e-02]\n",
            "\n",
            "Layer: dense_10\n",
            "Weights (W): (512, 256)\n",
            "[[ 0.00463485  0.0241717  -0.10021153 ... -0.04014053 -0.06174328\n",
            "  -0.09067857]\n",
            " [-0.08476007 -0.02740734 -0.07099751 ... -0.02130901 -0.01012122\n",
            "  -0.04045256]\n",
            " [-0.0070011   0.01284218  0.02052541 ... -0.04354575  0.05579525\n",
            "  -0.07834885]\n",
            " ...\n",
            " [ 0.01326666  0.05418072 -0.06266022 ...  0.00276207 -0.0457143\n",
            "   0.00360954]\n",
            " [-0.0479424  -0.02723416  0.09189231 ... -0.04307409 -0.06150194\n",
            "   0.04752924]\n",
            " [-0.01610129 -0.04361147 -0.04755775 ...  0.03060614 -0.04089915\n",
            "   0.09955916]]\n",
            "Biases (b): (256,)\n",
            "[-3.34405433e-03  1.70646969e-03 -1.93834526e-03  7.84302689e-03\n",
            "  9.45720263e-03 -7.19076255e-04 -2.88562686e-03  7.23025482e-03\n",
            " -5.17539075e-03 -4.78584273e-03  6.96351379e-03  4.41598287e-03\n",
            "  3.75594525e-03 -6.07128115e-03  2.99571245e-03  9.49603692e-03\n",
            "  1.51370708e-02 -7.47234881e-05  1.15057053e-02 -2.87461560e-03\n",
            " -1.19706960e-02  2.19559241e-02  1.61343516e-04  2.49874666e-02\n",
            "  1.25801293e-02  5.61932276e-04  1.12312818e-02  1.98111366e-02\n",
            "  3.83412726e-02  1.08100602e-03  1.58244688e-02 -3.37472744e-03\n",
            "  2.04412006e-02  1.24928886e-02  1.30158849e-02  1.04574403e-02\n",
            "  1.36548616e-02  1.37287341e-02 -3.67312838e-04 -1.49690243e-03\n",
            "  1.60712823e-02  2.49587372e-02  1.12977885e-02 -1.56217804e-02\n",
            " -1.91664346e-03  2.81227520e-03  1.58796238e-03  1.88257527e-02\n",
            "  3.26846465e-02 -7.94870220e-03 -1.88177582e-02 -5.69981243e-03\n",
            "  3.28244641e-02  1.79519597e-02  2.41545364e-02 -1.16290327e-03\n",
            "  1.93657130e-02  1.47146368e-02  1.44945513e-02  2.09147912e-02\n",
            " -1.61363948e-02 -6.60517626e-03  3.55507736e-03  3.27279908e-03\n",
            "  3.22103463e-02 -2.90331291e-03 -1.09768251e-03  8.78246687e-03\n",
            "  1.58203840e-02  6.65250234e-03  3.69815007e-02  3.38527607e-03\n",
            " -8.90178885e-03  1.17788306e-02  7.52322492e-04  1.00636445e-02\n",
            "  1.93740875e-02 -3.54771619e-03  2.43942179e-02 -4.65048524e-03\n",
            " -1.94413378e-03  2.15490274e-02  9.86598432e-04  3.62595922e-04\n",
            " -2.73939688e-03 -9.92389279e-04  1.36435553e-02  1.82989109e-02\n",
            "  1.85832195e-02 -1.16455113e-03 -8.73923860e-03 -5.61855780e-03\n",
            " -1.23931654e-02 -7.61086261e-03 -5.01003582e-03  2.98473611e-02\n",
            " -7.32775021e-04  7.91798346e-03  1.36621566e-02 -1.57824252e-03\n",
            "  2.25879368e-03 -4.82676877e-03 -1.33698771e-03  3.17650400e-02\n",
            "  1.31383138e-02  8.32618214e-03  9.98468790e-03  8.11390579e-03\n",
            "  2.72755306e-02 -3.76729039e-03  1.72398537e-02 -5.95440343e-03\n",
            "  7.06838211e-04  8.51338031e-04  1.83258541e-02 -6.34953205e-04\n",
            "  3.58493417e-03  9.17380955e-03  9.27776564e-03  1.74311176e-02\n",
            "  2.75302050e-03  2.88208593e-02  4.36829254e-02  3.49311121e-02\n",
            "  5.28939907e-03 -2.72664533e-04 -2.14216023e-04  1.83490850e-02\n",
            "  8.01883359e-03  2.87947636e-02  0.00000000e+00  2.57530790e-02\n",
            " -6.82153227e-03 -1.27099697e-02  1.13717942e-02  1.73664317e-02\n",
            " -4.62870114e-03  1.43127388e-03 -9.98306787e-04  1.20278047e-02\n",
            "  1.19960010e-02  2.61841808e-03  1.93075947e-02  2.25725379e-02\n",
            " -3.27604427e-03 -3.50728841e-03  9.33548203e-04  1.65509973e-02\n",
            " -6.11690991e-03  2.57660523e-02 -1.67027535e-03  2.68319920e-02\n",
            "  2.75819562e-02 -3.23435455e-03  1.45303765e-02  2.43735071e-02\n",
            " -4.84338868e-03 -9.81190894e-03  9.19331703e-03 -2.03444622e-03\n",
            "  7.16579147e-03  2.68759355e-02 -9.42834932e-03  1.46064376e-02\n",
            "  1.44997342e-02 -2.63090548e-03  1.93417445e-02  5.40302694e-03\n",
            "  1.42530380e-02  6.36654906e-04 -1.44566211e-03  5.29942708e-03\n",
            "  9.92173562e-04  7.38692889e-03 -3.06828134e-03  8.22955277e-03\n",
            "  1.62132189e-03  1.15861660e-02  8.94682296e-03 -2.67088157e-03\n",
            "  1.91297177e-02  9.44178842e-04 -5.13078878e-03  1.96924992e-02\n",
            "  4.23312769e-04  5.31624770e-03  9.33708902e-03  3.98203991e-02\n",
            "  9.22182947e-03  1.62437540e-02  1.18367570e-04  7.88431615e-03\n",
            "  1.83235463e-02 -7.48804677e-03  8.42790492e-03  2.34408993e-02\n",
            " -1.35413522e-03 -5.20584763e-05 -1.83264650e-02  5.30274846e-02\n",
            "  2.90269703e-02 -2.94633303e-03 -7.89854396e-03  7.23808911e-03\n",
            " -1.50484231e-03 -9.74102877e-03  1.33650005e-02  1.24223167e-02\n",
            "  3.79379303e-03  5.25285816e-03  9.61617101e-03 -2.14899005e-03\n",
            "  7.69418385e-03  8.98213685e-03 -7.19071319e-03  4.42888122e-03\n",
            "  3.04477639e-03  5.64923976e-05  7.93494470e-03  1.98689830e-02\n",
            "  1.14531750e-02  2.06428468e-02  1.86826363e-02 -1.24436906e-02\n",
            "  2.92335474e-03  5.74995810e-03  3.69157176e-03  2.56709894e-03\n",
            " -1.51256099e-02  1.22402282e-02 -1.37440697e-03  9.42673814e-03\n",
            "  3.98990745e-03  1.40818181e-02  2.34453380e-02  4.56997193e-03\n",
            "  4.26604133e-03  3.52954529e-02  2.20312104e-02  7.03583285e-03\n",
            " -1.35060190e-03  2.51770057e-02  3.69468180e-05  2.21723486e-02\n",
            "  2.22071167e-02 -2.37350874e-02  7.66109768e-03  1.32237989e-02\n",
            "  3.51428520e-03 -3.73224239e-03 -3.22578242e-04  5.64189209e-03\n",
            "  1.90259900e-03 -5.55932987e-03  2.78162044e-02  2.57672053e-02]\n",
            "\n",
            "Layer: dense_11\n",
            "Weights (W): (256, 128)\n",
            "[[-0.04082327 -0.00407956 -0.03543824 ... -0.0726692  -0.03264141\n",
            "  -0.04862716]\n",
            " [ 0.10872249 -0.00627922 -0.05466343 ...  0.04319213  0.0602994\n",
            "  -0.1112728 ]\n",
            " [ 0.03950212 -0.07129296  0.06007523 ...  0.11099865  0.10125471\n",
            "  -0.02793704]\n",
            " ...\n",
            " [-0.07930059 -0.03658091  0.07106162 ... -0.10678608  0.01561458\n",
            "  -0.05811444]\n",
            " [-0.06584907 -0.07938626 -0.04103909 ...  0.06931551 -0.08187248\n",
            "  -0.11129086]\n",
            " [-0.13284877 -0.0557473  -0.04366279 ... -0.01552092 -0.06843807\n",
            "   0.10280102]]\n",
            "Biases (b): (128,)\n",
            "[ 1.59694124e-02 -1.15955743e-04  2.93599982e-02 -3.41369468e-03\n",
            "  1.79751944e-02  2.01931875e-02  3.05217188e-02  3.09197023e-03\n",
            "  2.87768021e-02  3.71548869e-02  7.56421220e-03  6.66497566e-04\n",
            "  2.46703215e-02  1.18924258e-02  1.58748159e-03  1.82792656e-02\n",
            "  1.69574227e-02  7.93612096e-03  2.03601327e-02  1.06703900e-02\n",
            "  6.08757213e-02 -3.98214394e-03 -2.38113347e-02  2.72625182e-02\n",
            " -6.32161554e-03 -6.16068719e-03  9.57348384e-04  5.32833906e-03\n",
            "  2.80998070e-02  6.19844859e-03  3.14206444e-02  2.96449177e-02\n",
            "  2.62147989e-02  5.04658297e-02  1.91849992e-02 -1.24517968e-03\n",
            " -2.16698814e-02 -4.40231711e-03 -8.81706271e-03 -9.33511299e-04\n",
            "  1.31364278e-02  1.32193081e-02  4.91735875e-04  2.00202130e-03\n",
            "  1.89995561e-02 -3.02979467e-03  9.52217635e-03 -7.47217098e-03\n",
            "  4.34022844e-02  1.87358190e-03  2.13947129e-02  2.68520061e-02\n",
            "  2.65067108e-02  1.11874854e-02  2.20754743e-02  1.58466510e-02\n",
            "  1.48070496e-04  1.97671019e-02  1.51602225e-03  7.92297628e-03\n",
            "  2.44214833e-02  3.40168774e-02 -7.63558084e-03  6.34360965e-03\n",
            " -2.34251749e-03 -7.84180709e-04 -5.75727038e-03 -6.34227972e-03\n",
            " -4.14078729e-03 -6.67780987e-05  2.60050856e-02 -3.34978686e-03\n",
            " -8.84633325e-03  2.01496594e-02  2.12546177e-02 -2.74647702e-03\n",
            " -7.79113173e-03 -9.02536977e-03  1.32510625e-03 -7.08416570e-04\n",
            "  1.65351965e-02 -2.30315439e-02  9.48187429e-03  2.01501548e-02\n",
            " -5.80361718e-03 -6.73525129e-03  8.30290897e-04 -2.08866056e-02\n",
            " -2.50238460e-03  4.12386023e-02 -8.85161851e-03 -1.96260423e-03\n",
            "  1.81833608e-03 -6.49245083e-03  4.02761064e-03  3.43772772e-05\n",
            "  9.65718739e-03 -3.81682254e-03 -7.23297289e-03  2.60031708e-02\n",
            "  1.98293235e-02 -1.01817362e-02 -1.26467878e-02 -1.51937176e-03\n",
            "  2.91600041e-02  1.67912282e-02  3.27449292e-02  1.51784485e-02\n",
            "  4.09762785e-02  4.91908640e-02  1.25402948e-02  2.29045264e-02\n",
            "  4.37428337e-03  7.53582036e-03  4.35510054e-02  3.95415947e-02\n",
            " -7.83131865e-04  1.30092269e-02 -7.77752325e-03  2.38812296e-04\n",
            " -4.77908106e-05  2.89745759e-02  1.02724740e-02  3.35108233e-03\n",
            "  2.65989365e-05  1.84146315e-02  4.01598886e-02  7.44116376e-04]\n",
            "\n",
            "Layer: dense_12\n",
            "Weights (W): (128, 10)\n",
            "[[-0.02655256  0.21828747 -0.24903315 ... -0.26541674  0.05587206\n",
            "   0.02299172]\n",
            " [-0.05007616  0.11407343 -0.09732221 ... -0.04577922  0.09364665\n",
            "   0.06532961]\n",
            " [ 0.08819445 -0.05903593  0.00766397 ...  0.2914076  -0.17914854\n",
            "  -0.09699858]\n",
            " ...\n",
            " [ 0.3315461   0.11122054  0.0885912  ... -0.2870209  -0.0280935\n",
            "   0.1732993 ]\n",
            " [ 0.09781597 -0.31153107  0.09433247 ...  0.2033794  -0.35311818\n",
            "   0.39096707]\n",
            " [-0.17214923 -0.01888298  0.02503307 ...  0.02834234 -0.14240158\n",
            "   0.13703078]]\n",
            "Biases (b): (10,)\n",
            "[-0.02688503  0.03941404  0.00293909 -0.0538158   0.02560871  0.06993911\n",
            "  0.02793562 -0.00891841 -0.08218909  0.00597168]\n"
          ]
        }
      ]
    }
  ]
}